{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "microsoft": {
          "language": "python"
        },
        "collapsed": false
      },
      "source": [
        "%%pyspark \r\n",
        "\r\n",
        "from pyspark.sql.functions import explode\r\n",
        "from pyspark.sql.functions import col, concat_ws\r\n",
        "\r\n",
        "\r\n",
        "filewqual = \"esgupload/*\"\r\n",
        "\r\n",
        "### you need to change the path to point the containing folder of the esgupload folder. this folder must contain only\r\n",
        "###  files pushed from the power automate ESG extract flow\r\n",
        "thefile = \"abfss://workspace@stgbvnews.dfs.core.windows.net/\" + filewqual + \".json\"\r\n",
        "df_raw = spark.read.load(thefile, format='json')\r\n",
        "\r\n",
        "df_raw.printSchema()\r\n",
        "\r\n",
        "### flatten the phrases and referenced orgs\r\n",
        "\r\n",
        "\r\n",
        "ro = df_raw.select(df_raw.title, df_raw.excerpt, df_raw.phrases, df_raw.themes, df_raw.sentiment, df_raw.significance, df_raw.signals,  explode(df_raw.referencedOrgs).alias(\"refdOrg\"))\\\r\n",
        "                .withColumn(\"refdOrg\", col(\"refdOrg.name\"))\\\r\n",
        "                .withColumn(\"phrases\", concat_ws(\",\", col(\"phrases\")))\r\n",
        "\r\n",
        "ro.printSchema()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "### explode the signals and themes\r\n",
        "signals_ex = ro.select(ro.title,ro.excerpt, ro.phrases, ro.themes, ro.sentiment, ro.significance, ro.refdOrg, explode(ro.signals).alias(\"signal\"))\r\n",
        "df_final  = signals_ex.select(signals_ex.signal,\r\n",
        "    signals_ex.title,signals_ex.excerpt, signals_ex.phrases,  signals_ex.sentiment, signals_ex.significance, signals_ex.refdOrg, explode(signals_ex.themes).alias(\"theme\"))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS bitvorenews\")\r\n",
        "\r\n",
        "\r\n",
        "### overwrite the  table\r\n",
        "df_final.write.mode(\"overwrite\").saveAsTable(\"bitvorenews.sigtheme_ex\")\r\n",
        "\r\n",
        "df_final.printSchema()\r\n",
        "display(df_final.limit(100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "scala"
        },
        "collapsed": true
      },
      "source": [
        "%%spark\r\n",
        "val sql_write_df = spark.sql(\"SELECT title, significance, refdOrg, signal, theme, phrases, sentiment FROM bitvorenews.sigtheme_ex \")\r\n",
        "\r\n",
        "sql_write_df.write.mode(\"overwrite\").sqlanalytics(\"bitvoresql.dbo.sigtheme_all\", Constants.INTERNAL)"
      ]
    }
  ]
}