{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "microsoft": {}
      },
      "source": [
        "### Create a spark table for a Bitvore dataset in this case the public signals 2020\r\n",
        "### The dataset has gone through some preparation to be usable by the basic spark engine.\r\n",
        "### The following preparation of the .csv needs to be done before upload\r\n",
        "###     The text columns for title and excerpt were removed\r\n",
        "###     All commas and double quotes were removed\r\n",
        "\r\n",
        "\r\n",
        "%%pyspark\r\n",
        "\r\n",
        "from pyspark.sql.types import FloatType\r\n",
        "\r\n",
        "from pyspark.sql.functions import col, concat_ws\r\n",
        "from pyspark.sql.functions import *\r\n",
        "\r\n",
        "from pyspark.sql.types import TimestampType\r\n",
        "from pyspark.sql.functions import unix_timestamp\r\n",
        "\r\n",
        "### read the upload file into a dataframe\r\n",
        "filewqual = \"corp-signals-public-us-2020.csv\"\r\n",
        "\r\n",
        "### CHANGE THE @XXXXXX name to your storage workspace\r\n",
        "thefile = \"abfss://workspace@stgbvnews.dfs.core.windows.net/BitvoreDatasets/\" + filewqual\r\n",
        "\r\n",
        "df_raw = spark.read.options(header = 'True').csv(thefile)\r\n",
        "\r\n",
        "df_raw.printSchema()\r\n",
        "\r\n",
        "### Convert sentiment string to a float\r\n",
        "### Convert strings representing date / times to spark timestamps and extract dates to new cols\r\n",
        "df_conv = df_raw.withColumn(\"Sentiment\", df_raw.Sentiment.cast('float'))\\\r\n",
        "                .withColumn(\"AvailableAt\",unix_timestamp(\"AvailableAt\", 'MM/dd/yyyy HH:mm').cast(TimestampType()))\\\r\n",
        "                .withColumn(\"dateAvailable\", to_date(col(\"AvailableAt\")) )\\\r\n",
        "                .withColumn(\"PublishedAt\",unix_timestamp(\"PublishedAt\", 'MM/dd/yyyy HH:mm').cast(TimestampType()))\\\r\n",
        "                .withColumn(\"datePub\", to_date(col(\"PublishedAt\")) )\\\r\n",
        "                .withColumn(\"LastModified\",unix_timestamp(\"LastModified\", 'MM/dd/yyyy HH:mm').cast(TimestampType()))\\\r\n",
        "                .withColumn(\"dateLastModified\", to_date(col(\"LastModified\")) )\r\n",
        "\r\n",
        "\r\n",
        "df_conv.printSchema()\r\n",
        "\r\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS bitvorenews\")\r\n",
        "\r\n",
        "\r\n",
        "### overwrite the  table\r\n",
        "df_conv.write.mode(\"overwrite\").saveAsTable(\"bitvorenews.signalspublic2020\")\r\n",
        "\r\n",
        "\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "scala"
        },
        "collapsed": true
      },
      "source": [
        "%%spark\r\n",
        "val sql_write_df = spark.sql(\"SELECT * FROM bitvorenews.signalspublic2021\")\r\n",
        "\r\n",
        "sql_write_df.write.mode(\"overwrite\").sqlanalytics(\"bitvoresql.dbo.signalspublic2021\", Constants.INTERNAL)"
      ]
    }
  ]
}